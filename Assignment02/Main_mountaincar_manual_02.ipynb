{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MountainCar - manually playing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://gymnasium.farama.org/environments/classic_control/mountain_car/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try our second environment - MountainCar\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# I make 2 notebooks files because if (from gymnasium.utils import play) is using the same time with other library.\n",
    "# I am facing the issue kernal is crashed. \n",
    "# The Kernel crashed while executing code in the current cell or a previous cell.  Please review the code in the cell(s) to identify a possible cause of the failure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The point of this part of the exercise is to experiment with a custom code that attempts to solve the environment without RL algorithms. It's not probably feasible to actually solve this environment with a custom simple agent, but to experiment with the amount of variables and situations what has be taken into account while landing the car on top of the mountain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.44598672,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the env\n",
    "env = gym.make(\"MountainCar-v0\", render_mode='rgb_array', max_episode_steps=-1)\n",
    "\n",
    "# visualize the environment\n",
    "env.reset()\n",
    "#plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Precise Stopping on the Flag (Position Control)\n",
    "# Challenge: Stop exactly at position = 0.5 (the flag) without overshooting.\n",
    "# Why: Going even slightly over (like 0.501) can make the car slide down the other side and fail.\n",
    "\n",
    "# 2- Dealing with Slippery Surface\n",
    "# Challenge: The car keeps sliding due to momentum, even when action = 0.\n",
    "# Impact: It can drift past the flagpole after stopping.\n",
    "\n",
    "# 3- Mountain Slope Dynamics (We maky call it hill as well in our class that we are use to say)\n",
    "# Challenge: Steeper slopes cause faster downhill acceleration.\n",
    "\n",
    "# 4- Acceleration vs Deceleration \n",
    "# Challenge: If the car is still moving right near the top, it must push left to slow down. (As in some experiments its stopped above to flag)\n",
    "# Impact: Without this, it can fly past the flag or waste attempt.\n",
    "\n",
    "# 5-Starting Position\n",
    "# Challenge: The environment resets with random starting positions (typically between -0.6 and -0.4).\n",
    "# Impact: Agent logic must generalize to all valid start states so can’t rely on a fixed on.\n",
    "\n",
    "# 6- Right–Left Moment Swing\n",
    "# Challenge: The car needs to move back and forth to go up the hill.\n",
    "# Impact: If it doesn’t swing, it can’t reach the flag. (if velocity > 0.0 and position < 0.0: return 2)\n",
    "\n",
    "# 7-Early Termination by Braking Too Soon\n",
    "# Challenge: Stopping too early (like at 0.45) keeps the car from reaching the flag.\n",
    "# Impact: The car must stop very close to 0.5, or it will miss the flag.\n",
    "\n",
    "# 8- Controlling stopping over the flag\n",
    "# Challenge: If the car overshoots the peak, gravity will accelerate it downhill.\n",
    "# Impact: Must stop early and gently, or risk re-entering the pit.\n",
    "\n",
    "# 9- Most Importat Efficeincy in Rewards \n",
    "# Challenge: Maximize reward by reaching the goal in fewer steps — current logic doesn't optimize for that.\n",
    "\n",
    "# Further Optimization will be\n",
    "# Consider tuning parameters to not just reach the goal but reach it faster and cleaner.\n",
    "\n",
    "\n",
    "# I got best resutlts with all of experiments and challanges with these paramteres, I reached at goal and also took screenshots\n",
    "# These screenshots also attached last of this notebook, Also best code logic going to mention here\n",
    "\n",
    "#if position > 0.47:   return 0 if velocity > 0.0 and position < 0.0: return 2\n",
    "# if velocity < 0.0 and position > -0.50:       return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_agent(observation):\n",
    "    # get position and velocity\n",
    "    position, velocity = observation\n",
    "    if isinstance(velocity, dict) and len(velocity) == 0:\n",
    "        velocity = 0\n",
    "    if isinstance(position, np.ndarray):\n",
    "        position = position[0]\n",
    "    action = 1\n",
    "\n",
    "     # this might be between 0.05 - 0.1\n",
    "    if position > 0.47:\n",
    "        return 0\n",
    "    if velocity > 0.0 and position < 0.0:\n",
    "        return 2\n",
    "\n",
    "    if velocity < 0.0 and position > -0.50:\n",
    "        return 0\n",
    "\n",
    "    return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "clear_output(wait=True)\n",
    "plt.imshow(env.render())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Findings and explanation based on logs without altering code\n",
    "# Position shows where the car is on the mountain.\n",
    "# Velocity shows how fast and in which direction the car is moving.\n",
    "# When velocity is positive, the car is moving right (uphill).\n",
    "# When velocity is negative, the car is moving left (downhill).\n",
    "# Big position jumps show the car is moving quickly.\n",
    "# Change in position = +0.2541 its a  big jump to the right. Velocity: 0.0388 → A high positive value shows  car is moving fast uphill.\n",
    "# A large negative position (like -1.1) means the car is far left, and Fluctuations in position/velocity show the car is swinging back and forth to build momentum.\n",
    "# Positive velocity + increasing position = car is climbing and Negative velocity + decreasing position = car is falling back.\n",
    "\n",
    "\n",
    "\n",
    "# reset internal values in the environment\n",
    "# you can also lock down the random seed by using seed-parameter\n",
    "# i.e. env.reset(seed=123)\n",
    "observation = env.reset()\n",
    "\n",
    "# play the environment for 225 steps with our simple agent\n",
    "for step in range(225):\n",
    "    action = simple_agent(observation)\n",
    "\n",
    "    # get the feedback / observations from the environment after taking the step\n",
    "    observation, reward, done, info, truncate = env.step(action)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Position: {observation[0]}\")\n",
    "    print(f\"Velocity: {observation[1]}\")\n",
    "\n",
    "    # slow down the visual update\n",
    "    time.sleep(0.001)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screenshot was not showing, Thereby I just putted into the folder and now mentioning here names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two screenshots which is also addded into the repository with theses names\n",
    "# 1- Screenshot 2025-04-17 at 09.29.35\n",
    "# 2- Screenshot 2025-04-17 at 09.51.15\n",
    "\n",
    "# please review thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
